{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from transformers import *\n",
    "from tqdm.notebook import trange\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change device for GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv') \n",
    "df_train.shape\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv('dev.csv') \n",
    "df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv') \n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = df_train.columns\n",
    "label_cols = list(cols[3:])\n",
    "num_labels = len(label_cols)\n",
    "print('Label columns: ', label_cols)\n",
    "print(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1).reset_index(drop=True) #shuffle rows\n",
    "df_valid = df_valid.sample(frac=1).reset_index(drop=True) #shuffle rows\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True) #shuffle rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get one hots labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['one_hot_labels'] = list(df_train[label_cols].values)\n",
    "df_valid['one_hot_labels'] = list(df_valid[label_cols].values)\n",
    "df_test['one_hot_labels'] = list(df_test[label_cols].values)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_train[\"sum_labels\"] = df_train[cols[1:]].sum(axis=1)\n",
    "df_valid[\"sum_labels\"] = df_valid[cols[1:]].sum(axis=1)\n",
    "df_test[\"sum_labels\"] = df_test[cols[1:]].sum(axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = list(df_train.one_hot_labels.values)\n",
    "train_text = list(df_train.abstract.values)\n",
    "\n",
    "valid_labels = list(df_valid.one_hot_labels.values)\n",
    "valid_text = list(df_valid.abstract.values)\n",
    "\n",
    "test_labels = list(df_test.one_hot_labels.values)\n",
    "test_text = list(df_test.abstract.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=True) # tokenizer\n",
    "encodings_train = tokenizer.batch_encode_plus(train_text, max_length=max_length, padding='max_length', truncation=True) # tokenizer's encoding method\n",
    "print('tokenizer outputs: ', encodings_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_valid = tokenizer.batch_encode_plus(valid_text,max_length=max_length,padding='max_length',truncation=True) # tokenizer's encoding method\n",
    "print('tokenizer outputs: ', encodings_valid.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_test = tokenizer.batch_encode_plus(test_text,max_length=max_length,padding='max_length',truncation=True)\n",
    "print('tokenizer outputs: ', encodings_test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids = encodings_train['input_ids'] # tokenized and encoded sentences\n",
    "train_attention_masks = encodings_train['attention_mask'] # attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_input_ids = encodings_valid['input_ids'] # tokenized and encoded sentences\n",
    "valid_attention_masks = encodings_valid['attention_mask'] # attention masks\n",
    "test_input_ids = encodings_test['input_ids']\n",
    "test_attention_masks = encodings_test['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and save dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs_tensor = torch.tensor(train_input_ids)\n",
    "train_labels_tensor = torch.tensor(train_labels)\n",
    "train_masks_tensor = torch.tensor(train_attention_masks)\n",
    "\n",
    "validation_inputs_tensor = torch.tensor(valid_input_ids)\n",
    "validation_labels_tensor = torch.tensor(valid_labels)\n",
    "validation_masks_tensor = torch.tensor(valid_attention_masks)\n",
    "\n",
    "test_inputs_tensor = torch.tensor(test_input_ids)\n",
    "test_labels_tensor = torch.tensor(test_labels)\n",
    "test_masks_tensor = torch.tensor(test_attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning with XLNet, the authors recommend a batch size of 32, 48, or 128. We will use 32 here to avoid memory issues.\n",
    "batch_size = 8\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs_tensor, train_masks_tensor, train_labels_tensor)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs_tensor, validation_masks_tensor, validation_labels_tensor)\n",
    "validation_sampler = RandomSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(test_inputs_tensor, test_masks_tensor, test_labels_tensor)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataloader,'BERT/dataloaders/train_data_loader-8-512')\n",
    "torch.save(validation_dataloader,'BERT/dataloaders/validation_data_loader-8-512')\n",
    "torch.save(test_dataloader,'BERT/dataloaders/test_data_loader-8-512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
